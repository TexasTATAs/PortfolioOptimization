{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Optimization - Wasserstein Ball and Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Import Packages](#1)\n",
    "* [2. Stock Simulation Function](#2)  \n",
    "* [3. ANN for mapping State to action](#3)      \n",
    "* [4. Function toretun portfolio value and Risk Measure](#4)    \n",
    "* [5. Training](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2. Stock Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def SimPath(Ndt, S0, mu, sigma, T, Nsims):\n",
    "    \n",
    "    dt = T/Ndt\n",
    "    \n",
    "    S = np.zeros((Nsims,Ndt+1))\n",
    "    S[:,0] = S0\n",
    "    \n",
    "    for i in range(Ndt):\n",
    "        \n",
    "        dW = np.sqrt(dt) * np.random.randn(Nsims)\n",
    "        S[:,i+1] = S[:,i] * np.exp((mu-0.5*sigma**2)*dt + sigma*dW)\n",
    "        \n",
    "    t = np.linspace(0,T,Ndt+1)\n",
    "    return t, S\n",
    "        \n",
    "\n",
    "\n",
    "# %%\n",
    "t, S = SimPath(252,1, 0.1, 0.2, 5, 1000)\n",
    "\n",
    "# %%\n",
    "Ndt=20\n",
    "\n",
    "S0=1\n",
    "\n",
    "T=5\n",
    "\n",
    "Nsims=50\n",
    "\n",
    "\n",
    "plt.plot(t, S.T,linewidth=0.1)\n",
    "plt.plot(t,np.quantile(S,[0.1, 0.5, 0.9],axis=0).T,color='k',linewidth=2)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Asset Price $S_t$\")\n",
    "plt.xlim([0,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3. ANN for mapping state and weights\n",
    "In this function we pass the prices of the instruments and get the weights across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class MyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n ):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        # 3 input layer (t,S), 1 output channel, 3 hidden layers with n units each\n",
    "        self.f_in_to_h1 = nn.Linear( 4 , n)\n",
    "        self.f_h1_to_h2 = nn.Linear(n, n)\n",
    "        self.f_h2_to_out = nn.Linear(n, 3)\n",
    "        self.myReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input into 1st hidden layer\n",
    "        h1 = self.myReLU(self.f_in_to_h1(x) )\n",
    "        \n",
    "        # 1st hidden to 2nd hidden layer\n",
    "        h2 = self.myReLU(self.f_h1_to_h2(h1))\n",
    "            \n",
    "        # 2nd hidden layer to output layer\n",
    "        y = self.f_h2_to_out(h2)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3. Helper functions - Risk Measure and Wassterestein function\n",
    "This function fetches the Return, risk measure and portfolio path for each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRiskMeasure(Return, Type = \"TVaR\"):\n",
    "    #TVaR    \n",
    "    if (Type == \"TVaR\"):\n",
    "        percentile = 5\n",
    "        k = 1 + round(.01 * float(percentile) * (Return[1,:].numel() - 1))\n",
    "        RiskMeasure =  -1*Return.kthvalue(k).values\n",
    "        #RiskMeasure = torch.tensor(-1* np.percentile(Return.detach().numpy(), 5,axis=1), dtype=torch.float, requires_grad=True)\n",
    "    #Variance\n",
    "    elif (Type == \"Variance\"):  \n",
    "        RiskMeasure = torch.var(Return)   \n",
    "    return RiskMeasure        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWassDistance(TotalVal_T, IndexVal_T):\n",
    "    wd = stats.wasserstein_distance(TotalVal_T.detach(),IndexVal_T.detach())\n",
    "    wass_dist = torch.tensor(wd, dtype=torch.float, requires_grad=True)\n",
    "    \n",
    "    ## Other minimizations\n",
    "    #wd = stats.wasserstein_distance(wt[:,-1,0].detach(),Delta_t[:,-1,0].detach())\n",
    "    #wass_dist = wt-Delta_t\n",
    "    #wass_dist = wt[:,-1,:] - Delta_t[:,-1,:]\n",
    "    #wass_dist = (TotalVal_T - IndexVal_T)**2\n",
    "    return wass_dist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, S1 = SimPath(Ndt, 1, .05, .1, T, Nsims)\n",
    "t, S2 = SimPath(Ndt, 1, .06, .12, T, Nsims)\n",
    "t, S3 = SimPath(Ndt, 1, .06, .12, T, Nsims)\n",
    "\n",
    "t\n",
    "\n",
    "x=np.zeros((Nsims,Ndt+1,4))\n",
    "x.shape \n",
    "\n",
    "x[:,:,0] = np.matlib.repmat(t,Nsims, 1)\n",
    "\n",
    "x[:,:,1] = S1\n",
    "\n",
    "x[:,:,2] = S2\n",
    "\n",
    "x[:,:,3] = S3\n",
    "\n",
    "xt = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "wt= torch.tensor(np.zeros((Nsims,Ndt+1,3)), dtype=torch.float)\n",
    "\n",
    "wt[:,:-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt[:,1:,:] = net(xt[:,:-1,:])\n",
    "wt.shape\n",
    "\n",
    "#Compute wt\n",
    "#Set the t0 of the portfolio same as index\n",
    "wt[:,0,:] = Delta_t[:,0,:]\n",
    "\n",
    "S1.shape\n",
    "\n",
    "wt[:,:,1].shape\n",
    "\n",
    "wt \n",
    "\n",
    "S1[:,:-1].shape\n",
    "\n",
    "Val1= wt[:,:,0] * torch.tensor(S1, dtype=torch.float)\n",
    "Val2= wt[:,:,1] * torch.tensor(S2, dtype=torch.float)\n",
    "Val3= wt[:,:,2] * torch.tensor(S3, dtype=torch.float)\n",
    "TotalVal = Val1 + Val2 + Val3\n",
    "\n",
    "TotalVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights at time t \n",
    "#TotalVal[:, -1]\n",
    "\n",
    "x2=np.zeros((Nsims,Ndt-1))\n",
    "Return = torch.tensor(x2, dtype=torch.float)\n",
    "Return.shape\n",
    "\n",
    "for i in range(1,Ndt-1):\n",
    "    Return[:,i] = TotalVal[:,i+1] - TotalVal[:,i]\n",
    "        \n",
    "\n",
    "wt.shape\n",
    "\n",
    "#output for one scenario\n",
    "#wt[0,:,:]\n",
    "\n",
    "#Weight at T for all scenarios \n",
    "wt[:,-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_t = torch.tensor(np.zeros((Nsims,Ndt+1,3)), dtype=torch.float)\n",
    "Delta_t[:,:,0] = .50\n",
    "Delta_t[:,:,1] = .25\n",
    "Delta_t[:,:,2] = .25\n",
    "\n",
    "Val1_index= Delta_t[:,:,0] * torch.tensor(S1, dtype=torch.float, requires_grad=True)\n",
    "Val2_index= Delta_t[:,:,1] * torch.tensor(S2, dtype=torch.float, requires_grad=True)\n",
    "Val3_index= Delta_t[:,:,2] * torch.tensor(S2, dtype=torch.float, requires_grad=True)\n",
    "TotalVal_index = Val1_index + Val2_index + Val3_index\n",
    "#TotalVal_index[:, -1]\n",
    "Delta_t[:,-1,:].shape\n",
    "#np.array(TotalVal_index.detach())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Return = TotalVal[:,1:] - TotalVal[:,:-1] \n",
    "\n",
    "#Return at time T across all the scenarios\n",
    "Return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(TotalVal.detach()).mean(axis =0)\n",
    "\n",
    "#np.percentile(Return.detach().numpy(), 5, axis=1)\n",
    "\n",
    "RiskMeasure = torch.tensor(np.percentile(Return.detach().numpy(), 5,axis=1), dtype=torch.float, requires_grad=True)\n",
    "RiskMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wasserstein_distance(TotalVal_T.detach(),IndexVal_T.detach())\n",
    "\n",
    "#TotalVal_T\n",
    "\n",
    "#stats.wasserstein_distance(1,2)\n",
    "#TotalVal_T\n",
    "\n",
    "Return.shape\n",
    "\n",
    "Return.kthvalue(k).values\n",
    "\n",
    "percentile = 5\n",
    "k = 1 + round(.01 * float(percentile) * (Return[1,:].numel() - 1))\n",
    "Return.kthvalue(k).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Return[1,:].numel()\n",
    "\n",
    "round(.01 * float(.05) * (Return.numel() - 1))\n",
    "\n",
    "wt, Return, TVaR, TotalVal, TotalVal_T, TotalVal_index,IndexVal_T, wass_dist = SimTVaR(net, Ndt, T, Nsims, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other minimizations\n",
    "#wd = stats.wasserstein_distance(wt[:,-1,0].detach(),Delta_t[:,-1,0].detach())\n",
    "#wass_dist = wt-Delta_t\n",
    "#wass_dist = wt[:,-1,:] - Delta_t[:,-1,:]\n",
    "#wass_dist = (TotalVal_T - IndexVal_T)**2\n",
    "\n",
    "#Return at time T across all the scenarios     \n",
    "\n",
    "\n",
    "\n",
    "#TVaR   \n",
    "percentile = 5\n",
    "k = 1 + round(.01 * float(percentile) * (Return[1,:].numel() - 1))\n",
    "RiskMeasure =  -1*Return.kthvalue(k).values\n",
    "#RiskMeasure = torch.tensor(-1* np.percentile(Return.detach().numpy(), 5,axis=1), dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3. Function to get the Return, risk measure and portfolio weights\n",
    "This function fetches the Return, risk measure and portfolio path for each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndt = 100\n",
    "S1_T0 = 1\n",
    "S2_T0 = 100\n",
    "S3_T0 = 10\n",
    "Nsims = 50\n",
    "\n",
    "def SimTVaR(net, Ndt, T, Nsims, ReturnTensor):\n",
    "    \n",
    "    #The function is designed for 3 stocks. Can be customized for any number of stocks\n",
    "    num_asset = 3   \n",
    "    \n",
    "    t, S1 = SimPath(Ndt, S1_T0, .05, .1, T, Nsims)\n",
    "    t, S2 = SimPath(Ndt, S2_T0, .06, .12, T, Nsims)\n",
    "    t, S3 = SimPath(Ndt, S3_T0, .06, .12, T, Nsims)\n",
    "    \n",
    "    #Index Delta and return\n",
    "    Delta_t = torch.tensor(np.zeros((Nsims,Ndt+1,num_asset)), dtype=torch.float)\n",
    "    Delta_t[:,:,0] = .50\n",
    "    Delta_t[:,:,1] = .25\n",
    "    Delta_t[:,:,2] = .25\n",
    "\n",
    "    Val1_index= Delta_t[:,:,0] * torch.tensor(S1, dtype=torch.float, requires_grad=True)\n",
    "    Val2_index= Delta_t[:,:,1] * torch.tensor(S2, dtype=torch.float, requires_grad=True)\n",
    "    Val3_index= Delta_t[:,:,2] * torch.tensor(S3, dtype=torch.float, requires_grad=True)\n",
    "    TotalVal_index = Val1_index + Val2_index + Val3_index\n",
    "    IndexVal_T=TotalVal_index[:, -1]\n",
    "    \n",
    "    #Getting the weights for the portfolio\n",
    "    x=np.zeros((Nsims,Ndt+1,num_asset+1))   \n",
    "    x[:,:,1] = S1\n",
    "    x[:,:,2] = S2\n",
    "    x[:,:,3] = S3\n",
    "    xt = torch.tensor(x, dtype=torch.float)\n",
    "    wt= Delta_t\n",
    "    wt[:,1:,:] = net(xt[:,:-1,:])\n",
    "    #wt[:,0,:] = Delta_t[:,0,:]\n",
    "    Val1= wt[:,:,0] * torch.tensor(S1, dtype=torch.float)\n",
    "    Val2= wt[:,:,1] * torch.tensor(S2, dtype=torch.float)\n",
    "    Val3= wt[:,:,2] * torch.tensor(S3, dtype=torch.float)\n",
    "    TotalVal = Val1 + Val2 + Val3\n",
    "    TotalVal_T = TotalVal[:,-1]   \n",
    "    #Compute the return between two consecutive days\n",
    "    Return = TotalVal[:,1:] - TotalVal[:,:-1]  \n",
    "    \n",
    "    \n",
    "    # Compute the risk measure and wasstertein Distance for the computation\n",
    "    wass_dist = getWassDistance(TotalVal_T, IndexVal_T)\n",
    "    RiskMeasure = GetRiskMeasure(Return, \"TVaR\")    \n",
    "    \n",
    "    return wt, Return, RiskMeasure, TotalVal, TotalVal_index, TotalVal_T, IndexVal_T, wass_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#print('Using device:', device)\n",
    "#net.to(device)\n",
    "\n",
    "#print(net)\n",
    "\n",
    "#Create object of the class\n",
    "net = MyNet(80)\n",
    "\n",
    "# create  optimizer\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "\n",
    "Nepochs = 10000\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(Nepochs):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    #hedge_payoff, true_payoff, S = SimHedge(net, Ndt, S0, mu, sigma, T, Nsims, True)\n",
    "    wt, Return, RiskMeasure, TotalVal, TotalVal_index, TotalVal_T, IndexVal_T, wass_dist = SimTVaR(net, Ndt, T, Nsims, True)\n",
    "    \n",
    "    #print (S )\n",
    "    #error = wass_dist + TVaR\n",
    "    #print (error )\n",
    "    regularization_param = 1\n",
    "    loss = regularization_param*torch.sum(wass_dist) + torch.sum(RiskMeasure)\n",
    "    #loss = torch.sum(-TVaR)\n",
    "    #print (wt) \n",
    "    loss.backward()   \n",
    "    \n",
    "    #print (wt, Return, TVaR ) \n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    \n",
    "    # store running loss\n",
    "    loss_hist.append(  loss.item() )\n",
    "    \n",
    "    # plot output every 50 iterations\n",
    "    if( (epoch % 500 == 0) and (epoch>1) ):\n",
    "        print(epoch,end=\" \")\n",
    "        #print(loss.item())\n",
    "        print(\"Wass Dist:\", regularization_param*torch.sum(wass_dist**2))\n",
    "        print(\"Risk Measure:\", torch.sum(RiskMeasure))\n",
    "        sns.distplot(np.array(IndexVal_T.detach()), hist=True, kde=True, label='Index')\n",
    "        sns.distplot(np.array(TotalVal_T.detach()), hist=True, kde=True, label='Portfolio')\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(loss_hist)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(np.array(TotalVal_index.detach())[0], label='Index')\n",
    "        plt.plot(np.array(TotalVal.detach())[0], label='Portfolio')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Code for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
